{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Starting Kit - Black Swan HiggsML Course\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = \"google.colab\" in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    ! git clone --depth 1 https://github.com/blackSwanCS/Higgs_collaborations.git\n",
    "\n",
    "    ! git status\n",
    "    %cd Higgs_collaborations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HiggsML utility package should not be modified\n",
    "%pip install HiggsML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from numpy.random import RandomState\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "print(\"Root directory is\", root_dir)\n",
    "submission_dir = os.path.join(root_dir, \"sample_code_submission\")\n",
    "\n",
    "# The directory where results and other outputs from the participant's code will be written\n",
    "output_dir = os.path.join(root_dir, \"sample_result_submission\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Submission Model\n",
    "We import a class named `Model` from the submission file (`model.py`). This `Model` class has the following methods:\n",
    "- `init`: receives train set and systematics class as input\n",
    "- `fit`: can be used for training\n",
    "- `predict`: receives one test set and outputs a dictionary with the following keys\n",
    "    - `mu_hat` : predicted mu $\\hat{\\mu}$\n",
    "    - `delta_mu_hat`: $\\Delta{\\hat{\\mu}}$ bound for $\\mu$\n",
    "    - `p16`: 16th percentile\n",
    "    - `p84`: 84th percentile\n",
    "\n",
    "In this example code, the `Model` class implements a basic model with 2 different model trained to predict the class label. \n",
    "\n",
    "* 1 XGBoost BDT ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/boosted_decision_tree.py) )\n",
    "* 2 Tebsorflow NN  ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/neural_network.py) )\n",
    "\n",
    "The feature engineering is in where you can include derived quantities and decide which feature should be needed. ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/feature_engineering.py) ) \n",
    "\n",
    "the statistical analysis part is where yoiu write the mu finding calculation using the output of the classifier. ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/statistical_analysis.py) ) \n",
    "\n",
    "If running in Collab, click the folder icon in the left sidebar to open the file browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.append(submission_dir)\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Available data sets\n",
    "1. blackSwan_data\n",
    "2. sample_data\n",
    "3. neurips2024_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.datasets import download_dataset\n",
    "\n",
    "data = download_dataset(\n",
    "    \"blackSwan_data\"\n",
    ")  # change to \"blackSwan_data\" for the actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️ Note:\n",
    "The data used here is a small subset of the full data is for demonstration only to get a view of what the data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train set\n",
    "data.load_train_set()\n",
    "data_set = data.get_train_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Visualize the Data Set\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "target = data_set[\"labels\"]\n",
    "weights = data_set[\"weights\"]\n",
    "detailed_label = data_set[\"detailed_labels\"]\n",
    "keys = np.unique(detailed_label)\n",
    "\n",
    "\n",
    "weight_keys = {}\n",
    "average_weights = {}\n",
    "for key in keys:\n",
    "    weight_keys[key] = weights[detailed_label == key]\n",
    "\n",
    "table_data = []\n",
    "for key in keys:\n",
    "    table_data.append(\n",
    "        [\n",
    "            key,\n",
    "            np.sum(weight_keys[key]),\n",
    "            len(weight_keys[key]),\n",
    "            np.mean(weight_keys[key]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "table_data.append(\n",
    "    [\n",
    "        \"Total Signal\",\n",
    "        np.sum(weights[target == 1]),\n",
    "        len(weights[target == 1]),\n",
    "        np.mean(weights[target == 1]),\n",
    "    ]\n",
    ")\n",
    "table_data.append(\n",
    "    [\n",
    "        \"Total Background\",\n",
    "        np.sum(weights[target == 0]),\n",
    "        len(weights[target == 0]),\n",
    "        np.mean(weights[target == 0]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"[*] --- Detailed Label Summary\")\n",
    "print(\n",
    "    tabulate(\n",
    "        table_data,\n",
    "        headers=[\n",
    "            \"Detailed Label\",\n",
    "            \"Total Weight\",\n",
    "            \"Number of events\",\n",
    "            \"Average Weight\",\n",
    "        ],\n",
    "        tablefmt=\"grid\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[*] --- Examples of all features\\n\")\n",
    "display(data_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[*] --- Description of all features\\n\")\n",
    "display(data_set.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import histogram_dataset\n",
    "\n",
    "feature_columns = [col for col in data_set.columns if col.startswith(\"PRI_\") or col.startswith(\"DER_\")]\n",
    "\n",
    "for i in range(0, len(feature_columns), 4):\n",
    "    subset = feature_columns[i:i+4]\n",
    "    histogram_dataset(data_set, data_set[\"labels\"], data_set[\"weights\"], columns=subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import histogram_dataset\n",
    "\n",
    "# this function is defined in utils.py in the sample_code_submission directory. feel free to modify it as needed\n",
    "\n",
    "histogram_dataset(\n",
    "    data_set,\n",
    "    target,\n",
    "    weights,\n",
    "    columns=[\"PRI_lep_phi\", \"PRI_met\", \"DER_mass_vis\", \"DER_deltaeta_jet_jet\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(rc={\"figure.figsize\": (10, 10)}, style=\"whitegrid\")\n",
    "\n",
    "caption = [\"Signal feature\", \"Background feature\"]\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    dfplot = pd.DataFrame(\n",
    "        data_set,\n",
    "        columns=[\n",
    "            \"PRI_lep_phi\",\n",
    "            \"PRI_met\",\n",
    "            \"DER_pt_ratio_lep_had\",\n",
    "            \"DER_deltaeta_jet_jet\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(caption[i], \" correlation matrix\")\n",
    "    corrMatrix = dfplot[target == i].corr()\n",
    "    sns.heatmap(corrMatrix, annot=True)\n",
    "    plt.title(\"Correlation matrix of features\")\n",
    "    plt.show()\n",
    "\n",
    "del dfplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.visualization import stacked_histogram\n",
    "\n",
    "stacked_histogram(data_set, target, weights, detailed_label, \"PRI_jet_subleading_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.visualization import pair_plots\n",
    "\n",
    "# Show data summary\n",
    "pair_plots(\n",
    "    data_set,\n",
    "    target,\n",
    "    sample_size=100,\n",
    "    columns=[\n",
    "        \"PRI_lep_phi\",\n",
    "        \"PRI_met\",\n",
    "        \"DER_lep_eta_centrality\",\n",
    "        \"DER_deltaeta_jet_jet\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from HiggsML.datasets import download_dataset\n",
    "\n",
    "data = download_dataset(\"blackSwan_data\")\n",
    "data.load_train_set()\n",
    "train_set = data.get_train_set()\n",
    "\n",
    "# 模拟系统偏差：选择一种\n",
    "bias_type = \"jes\"         # 可选项：\"jes\", \"tes\", \"soft_met\"\n",
    "bias_magnitude = 0.01     # 对应 sigma 值，可以设为 ±0.01\n",
    "\n",
    "# 构建偏置版本的数据\n",
    "biased_train = train_set.copy()\n",
    "\n",
    "if bias_type == \"jes\":\n",
    "    factor = 1.0 + bias_magnitude\n",
    "    for feature in [\"PRI_met\", \"PRI_jet_leading_pt\", \"PRI_jet_subleading_pt\"]:\n",
    "        if feature in biased_train.columns:\n",
    "            biased_train[feature] *= factor\n",
    "\n",
    "elif bias_type == \"tes\":\n",
    "    factor = 1.0 + bias_magnitude\n",
    "    if \"PRI_tau_pt\" in biased_train.columns:\n",
    "        biased_train[\"PRI_tau_pt\"] *= factor\n",
    "\n",
    "elif bias_type == \"soft_met\":\n",
    "    if \"PRI_met\" in biased_train.columns:\n",
    "        biased_train[\"PRI_met\"] += 20  # 加性偏差示例\n",
    "\n",
    "# 可视化受影响的特征\n",
    "affected_features = [\"PRI_met\", \"PRI_jet_leading_pt\", \"PRI_jet_subleading_pt\", \"PRI_tau_pt\"]\n",
    "\n",
    "labels = train_set[\"labels\"]\n",
    "weights = train_set[\"weights\"]\n",
    "sig = train_set[labels == 1]\n",
    "bkg = train_set[labels == 0]\n",
    "sig_biased = biased_train[labels == 1]\n",
    "bkg_biased = biased_train[labels == 0]\n",
    "\n",
    "for feature in affected_features:\n",
    "    if feature not in train_set.columns:\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(sig[feature], bins=50, weights=weights[labels == 1], label=\"Signal (original)\", color=\"red\", alpha=0.4, density=True)\n",
    "    plt.hist(sig_biased[feature], bins=50, weights=weights[labels == 1], label=\"Signal (biased)\", color=\"red\", histtype=\"step\", linewidth=2)\n",
    "\n",
    "    plt.hist(bkg[feature], bins=50, weights=weights[labels == 0], label=\"Background (original)\", color=\"blue\", alpha=0.4, density=True)\n",
    "    plt.hist(bkg_biased[feature], bins=50, weights=weights[labels == 0], label=\"Background (biased)\", color=\"blue\", histtype=\"step\", linewidth=2)\n",
    "\n",
    "    plt.title(f\"{feature}: Effect of {bias_type.upper()} Bias (+{bias_magnitude*100:.1f}%)\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def apply_systematics_full(\n",
    "    df, \n",
    "    alpha_tes=1.0, \n",
    "    alpha_jes=1.0, \n",
    "    alpha_soft_met=0.0, \n",
    "    alpha_ttbar_scale=1.0, \n",
    "    alpha_diboson_scale=1.0, \n",
    "    alpha_bkg_scale=1.0,\n",
    "    enforce_threshold=True,\n",
    "    threshold_value=26\n",
    "):\n",
    "    df = df.copy()\n",
    "\n",
    "    # TES: adjust tau pt\n",
    "    if \"PRI_tau_pt\" in df.columns:\n",
    "        df[\"PRI_tau_pt\"] *= alpha_tes\n",
    "\n",
    "    # JES: adjust jets pt\n",
    "    for feat in [\"PRI_jet_leading_pt\", \"PRI_jet_subleading_pt\", \"PRI_jet_all_pt\"]:\n",
    "        if feat in df.columns:\n",
    "            df[feat] *= alpha_jes\n",
    "\n",
    "    # Apply event threshold after JES/TES (to hide bias signature)\n",
    "    if enforce_threshold:\n",
    "        for feat in [\"PRI_tau_pt\", \"PRI_jet_leading_pt\", \"PRI_jet_subleading_pt\"]:\n",
    "            if feat in df.columns:\n",
    "                df = df[df[feat] > threshold_value]\n",
    "\n",
    "    # Soft MET: apply additive 2D noise to PRI_met\n",
    "    if \"PRI_met\" in df.columns and alpha_soft_met > 0.0:\n",
    "        soft_noise_px = np.random.normal(0, alpha_soft_met, size=len(df))\n",
    "        soft_noise_py = np.random.normal(0, alpha_soft_met, size=len(df))\n",
    "        soft_et = np.sqrt(soft_noise_px**2 + soft_noise_py**2)\n",
    "        df[\"PRI_met\"] += soft_et\n",
    "\n",
    "    # Weight biases (background only)\n",
    "    if \"labels\" in df.columns and \"weights\" in df.columns and \"detailed_labels\" in df.columns:\n",
    "        weights = df[\"weights\"].copy()\n",
    "        is_bkg = df[\"labels\"] == 0\n",
    "\n",
    "        # Start with base background scaling\n",
    "        weights[is_bkg] *= alpha_bkg_scale\n",
    "\n",
    "        # ttbar background\n",
    "        weights[(df[\"detailed_labels\"] == \"ttbar\")] *= alpha_ttbar_scale\n",
    "\n",
    "        # diboson background\n",
    "        weights[(df[\"detailed_labels\"] == \"diboson\")] *= alpha_diboson_scale\n",
    "\n",
    "        df[\"weights\"] = weights\n",
    "\n",
    "    return df\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 应用偏差（示例：JES 上调1%，Soft MET 加噪声）\n",
    "biased_df = apply_systematics_full(\n",
    "    train_set,\n",
    "    alpha_jes=1.01,\n",
    "    alpha_soft_met=15,  # 高斯噪声标准差\n",
    "    alpha_tes=1.0,\n",
    "    alpha_ttbar_scale=1.0,\n",
    "    alpha_diboson_scale=1.0,\n",
    "    alpha_bkg_scale=1.0,\n",
    "    enforce_threshold=False\n",
    ")\n",
    "\n",
    "# 可视化影响的主要特征\n",
    "features = [\"PRI_jet_leading_pt\", \"PRI_jet_subleading_pt\", \"PRI_met\", \"PRI_tau_pt\"]\n",
    "labels = train_set[\"labels\"]\n",
    "weights = train_set[\"weights\"]\n",
    "\n",
    "biased_labels = biased_df[\"labels\"]\n",
    "biased_weights = biased_df[\"weights\"]\n",
    "\n",
    "for feat in features:\n",
    "    if feat not in train_set.columns or feat not in biased_df.columns:\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    # 原始数据（Signal + Background）\n",
    "    plt.hist(train_set[feat][labels == 1], bins=50, weights=weights[labels == 1]*100, \n",
    "             label=\"Signal (original)\", color=\"red\", alpha=0.3, density=False)\n",
    "    plt.hist(train_set[feat][labels == 0], bins=50, weights=weights[labels == 0], \n",
    "             label=\"Background (original)\", color=\"blue\", alpha=0.3, density=False)\n",
    "\n",
    "    # 有偏数据（Signal + Background）\n",
    "    plt.hist(biased_df[feat][biased_labels == 1], bins=50, weights=biased_weights[biased_labels == 1]*100, \n",
    "             label=\"Signal (biased)\", histtype=\"step\", color=\"red\", linewidth=1.5)\n",
    "    plt.hist(biased_df[feat][biased_labels == 0], bins=50, weights=biased_weights[biased_labels == 0], \n",
    "             label=\"Background (biased)\", histtype=\"step\", color=\"blue\", linewidth=1.5)\n",
    "\n",
    "    plt.title(f\"{feat} — with JES=1.01, SoftMET noise=15\")\n",
    "    plt.xlabel(feat)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Original signal samples:\", sum(labels == 1))\n",
    "print(\"Original background samples:\", sum(labels == 0))\n",
    "print(\"Biased signal samples:\", sum(biased_labels == 1))\n",
    "print(\"Biased background samples:\", sum(biased_labels == 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Signal weight sum:\", weights[labels == 1].sum())\n",
    "print(\"Background weight sum:\", weights[labels == 0].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from systematics import systematics\n",
    "\n",
    "# # ==== 加载原始数据集（假设你已经有 original_df） ====\n",
    "# # 如果没有，请先运行：\n",
    "# data.load_train_set()\n",
    "# original_df = data.get_train_set()\n",
    "\n",
    "# # ==== 应用系统偏差 ====\n",
    "# biased_df = systematics(\n",
    "#     {\"data\": original_df, \"weights\": np.ones(len(original_df))},\n",
    "#     tes=1.01,\n",
    "#     jes=1.01,\n",
    "#     soft_met=15,\n",
    "#     ttbar_scale=1.0,\n",
    "#     diboson_scale=1.0,\n",
    "#     bkg_scale=1.0,\n",
    "#     dopostprocess=False\n",
    "# )[\"data\"]\n",
    "\n",
    "# # ==== 可视化设置 ====\n",
    "# features = [\"PRI_tau_pt\", \"PRI_jet_leading_pt\", \"PRI_jet_subleading_pt\", \"PRI_met\"]\n",
    "# colors = {\n",
    "#     \"Signal (original)\": \"red\",\n",
    "#     \"Signal (biased)\": \"darkred\",\n",
    "#     \"Background (original)\": \"blue\",\n",
    "#     \"Background (biased)\": \"darkblue\"\n",
    "# }\n",
    "\n",
    "# labels = original_df[\"labels\"]\n",
    "# weights = original_df[\"weights\"]\n",
    "\n",
    "# biased_labels = biased_df[\"labels\"]\n",
    "# biased_weights = biased_df[\"weights\"]\n",
    "\n",
    "# # ==== 画图 ====\n",
    "# for feat in features:\n",
    "#     if feat not in original_df.columns or feat not in biased_df.columns:\n",
    "#         continue\n",
    "\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "\n",
    "#     # 原始数据\n",
    "#     plt.hist(original_df[feat][labels == 1], bins=50, weights=weights[labels == 1],\n",
    "#              label=\"Signal (original)\", color=colors[\"Signal (original)\"], alpha=0.25, density=True)\n",
    "#     plt.hist(original_df[feat][labels == 0], bins=50, weights=weights[labels == 0],\n",
    "#              label=\"Background (original)\", color=colors[\"Background (original)\"], alpha=0.25, density=True)\n",
    "\n",
    "#     # 有偏数据\n",
    "#     plt.hist(biased_df[feat][biased_labels == 1], bins=50, weights=biased_weights[biased_labels == 1],\n",
    "#              label=\"Signal (biased)\", histtype=\"step\", color=colors[\"Signal (biased)\"], linewidth=1.5, density=True)\n",
    "#     plt.hist(biased_df[feat][biased_labels == 0], bins=50, weights=biased_weights[biased_labels == 0],\n",
    "#              label=\"Background (biased)\", histtype=\"step\", color=colors[\"Background (biased)\"], linewidth=1.5, density=True)\n",
    "\n",
    "#     plt.title(f\"{feat} — effect of JES+TES+SoftMET\")\n",
    "#     plt.xlabel(feat)\n",
    "#     plt.ylabel(\"Density (normalized)\")\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from HiggsML.systematics import systematics\n",
    "\n",
    "# ==== Load the original dataset original_df ====\n",
    "data.load_train_set()\n",
    "original_df = data.get_train_set()\n",
    "\n",
    "# === Apply systematic biases and extract data and weights ===\n",
    "biased = systematics(\n",
    "    {\"data\": original_df, \"weights\": np.ones(len(original_df))},\n",
    "    tes=1.01,\n",
    "    jes=1.01,\n",
    "    soft_met=15,\n",
    "    ttbar_scale=1.0,\n",
    "    diboson_scale=1.0,\n",
    "    bkg_scale=1.0,\n",
    "    dopostprocess=False\n",
    ")\n",
    "\n",
    "biased_df = biased[\"data\"]\n",
    "biased_weights = biased[\"weights\"]\n",
    "\n",
    "# === Visualize affected features ===\n",
    "features = [\"PRI_had_pt\", \"PRI_jet_leading_pt\", \"PRI_jet_subleading_pt\", \"PRI_met\"]\n",
    "labels = original_df[\"labels\"]\n",
    "weights = original_df[\"weights\"]\n",
    "biased_labels = biased_df[\"labels\"]\n",
    "\n",
    "for feat in features:\n",
    "    if feat not in original_df.columns or feat not in biased_df.columns:\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    # Original signal and background\n",
    "    plt.hist(original_df[feat][labels == 1], bins=100, weights=weights[labels == 1],\n",
    "             label=\"Signal (original)\", color=\"red\", alpha=0.25, density=True)\n",
    "    plt.hist(original_df[feat][labels == 0], bins=100, weights=weights[labels == 0],\n",
    "             label=\"Background (original)\", color=\"blue\", alpha=0.25, density=True)\n",
    "\n",
    "    # Biased signal and background\n",
    "    plt.hist(biased_df[feat][biased_labels == 1], bins=100, weights=biased_weights[biased_labels == 1],\n",
    "             label=\"Signal (biased)\", histtype=\"step\", color=\"darkred\", linewidth=1.5, density=True)\n",
    "    plt.hist(biased_df[feat][biased_labels == 0], bins=100, weights=biased_weights[biased_labels == 0],\n",
    "             label=\"Background (biased)\", histtype=\"step\", color=\"darkblue\", linewidth=1.5, density=True)\n",
    "\n",
    "    plt.title(f\"{feat} — effect of JES+TES+SoftMET\")\n",
    "    plt.xlabel(feat)\n",
    "    plt.ylabel(\"Density (normalized)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in original_df:\", original_df.columns.tolist())\n",
    "print(\"Columns in biased_df:\", biased_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始信号 + 背景总数\n",
    "print(\"Full original signal:\", (original_df[\"labels\"] == 1).sum())\n",
    "print(\"Full original background:\", (original_df[\"labels\"] == 0).sum())\n",
    "\n",
    "# 当前参与绘图的信号/背景数量\n",
    "print(\"Filtered signal used in plot:\", sig.shape[0])\n",
    "print(\"Filtered background used in plot:\", bkg.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from HiggsML.systematics import systematics\n",
    "\n",
    "# ==== Load the original dataset ====\n",
    "data.load_train_set()\n",
    "original_df = data.get_train_set()\n",
    "\n",
    "# === Apply systematic biases ===\n",
    "biased = systematics(\n",
    "    {\"data\": original_df, \"weights\": np.ones(len(original_df))},\n",
    "    tes=1.01,\n",
    "    jes=1.01,\n",
    "    soft_met=15,\n",
    "    ttbar_scale=1.0,\n",
    "    diboson_scale=1.0,\n",
    "    bkg_scale=1.0,\n",
    "    dopostprocess=False\n",
    ")\n",
    "\n",
    "biased_df = biased[\"data\"]\n",
    "biased_weights = biased[\"weights\"]\n",
    "\n",
    "# === Define features to visualize ===\n",
    "features = [\"PRI_had_pt\", \"PRI_jet_leading_pt\", \"PRI_jet_subleading_pt\", \"PRI_met\"]\n",
    "labels = original_df[\"labels\"]\n",
    "weights = original_df[\"weights\"]\n",
    "biased_labels = biased_df[\"labels\"]\n",
    "\n",
    "for feat in features:\n",
    "    if feat not in original_df.columns or feat not in biased_df.columns:\n",
    "        continue\n",
    "\n",
    "    # Combine all relevant values (original + biased) to compute robust x-axis range\n",
    "    all_vals = pd.concat([original_df[feat], biased_df[feat]]).dropna()\n",
    "    x_min, x_max = np.percentile(all_vals, [0.5, 99.5])  # Automatically clip extreme outliers\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    # Original signal and background\n",
    "    plt.hist(original_df[feat][labels == 1], bins=120, weights=weights[labels == 1],\n",
    "             label=\"Signal (original)\", color=\"red\", alpha=0.25, density=True)\n",
    "    plt.hist(original_df[feat][labels == 0], bins=120, weights=weights[labels == 0],\n",
    "             label=\"Background (original)\", color=\"blue\", alpha=0.25, density=True)\n",
    "\n",
    "    # Biased signal and background\n",
    "    plt.hist(biased_df[feat][biased_labels == 1], bins=120, weights=biased_weights[biased_labels == 1],\n",
    "             label=\"Signal (biased)\", histtype=\"step\", color=\"darkred\", linewidth=1.5, density=True)\n",
    "    plt.hist(biased_df[feat][biased_labels == 0], bins=120, weights=biased_weights[biased_labels == 0],\n",
    "             label=\"Background (biased)\", histtype=\"step\", color=\"darkblue\", linewidth=1.5, density=True)\n",
    "\n",
    "    # Automatically set x-axis limit based on feature's central range\n",
    "    plt.xlim(x_min, x_max)\n",
    "\n",
    "    plt.title(f\"{feat} — effect of JES+TES+SoftMET\")\n",
    "    plt.xlabel(feat)\n",
    "    plt.ylabel(\"Density (normalized)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from HiggsML.systematics import systematics\n",
    "\n",
    "# === Load original dataset ===\n",
    "data.load_train_set()\n",
    "original_df = data.get_train_set()\n",
    "\n",
    "# === Apply systematic shifts ===\n",
    "biased = systematics(\n",
    "    {\"data\": original_df, \"weights\": np.ones(len(original_df))},\n",
    "    tes=1.01,\n",
    "    jes=1.,\n",
    "    soft_met=15,\n",
    "    ttbar_scale=1.0,\n",
    "    diboson_scale=1.0,\n",
    "    bkg_scale=1.0,\n",
    "    dopostprocess=False\n",
    ")\n",
    "\n",
    "biased_df = biased[\"data\"]\n",
    "biased_weights = biased[\"weights\"]\n",
    "\n",
    "labels = original_df[\"labels\"]\n",
    "weights = original_df[\"weights\"]\n",
    "biased_labels = biased_df[\"labels\"]\n",
    "\n",
    "# === Features to visualize ===\n",
    "features = [\"PRI_had_pt\", \"PRI_jet_leading_pt\", \"PRI_jet_subleading_pt\", \"PRI_met\"]\n",
    "\n",
    "# === Helper: compute Freedman-Diaconis bin edges ===\n",
    "def compute_fd_bins(data, max_bins=100):\n",
    "    data = np.asarray(data)\n",
    "    data = data[np.isfinite(data)]\n",
    "    if len(data) < 2:\n",
    "        return np.array([data[0], data[0] + 1])\n",
    "    q25, q75 = np.percentile(data, [25, 75])\n",
    "    iqr = q75 - q25\n",
    "    bin_width = 2 * iqr / np.cbrt(len(data))\n",
    "    if bin_width <= 0:\n",
    "        return np.linspace(np.min(data), np.max(data), 10)\n",
    "    bins = int(np.ceil((data.max() - data.min()) / bin_width))\n",
    "    bins = min(bins, max_bins)\n",
    "    return np.linspace(data.min(), data.max(), bins + 1)\n",
    "\n",
    "# === Visualization ===\n",
    "for feat in features:\n",
    "    if feat not in original_df.columns or feat not in biased_df.columns:\n",
    "        continue\n",
    "\n",
    "    # Combine all data for bin estimation\n",
    "    data_all = pd.concat([\n",
    "        original_df[feat][labels == 1],\n",
    "        original_df[feat][labels == 0],\n",
    "        biased_df[feat][biased_labels == 1],\n",
    "        biased_df[feat][biased_labels == 0]\n",
    "    ])\n",
    "    bin_edges = compute_fd_bins(data_all)\n",
    "    if feat == \"PRI_had_pt\":\n",
    "        print(\"test\")\n",
    "        print(original_df[feat][labels == 1])\n",
    "        print(biased_df[feat][biased_labels == 1])\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    # Original signal and background\n",
    "    plt.hist(original_df[feat][labels == 1], bins=bin_edges, weights=weights[labels == 1],\n",
    "             label=\"Signal (original)\", color=\"red\", alpha=0.25, density=True)\n",
    "    plt.hist(original_df[feat][labels == 0], bins=bin_edges, weights=weights[labels == 0],\n",
    "             label=\"Background (original)\", color=\"blue\", alpha=0.25, density=True)\n",
    "\n",
    "    # Biased signal and background\n",
    "    plt.hist(biased_df[feat][biased_labels == 1], bins=bin_edges, weights=biased_weights[biased_labels == 1],\n",
    "             label=\"Signal (biased)\", histtype=\"step\", color=\"darkred\", linewidth=1.5, density=True)\n",
    "    plt.hist(biased_df[feat][biased_labels == 0], bins=bin_edges, weights=biased_weights[biased_labels == 0],\n",
    "             label=\"Background (biased)\", histtype=\"step\", color=\"darkblue\", linewidth=1.5, density=True)\n",
    "\n",
    "    plt.title(f\"{feat} — effect of JES+TES+SoftMET\")\n",
    "    plt.xlabel(feat)\n",
    "    plt.ylabel(\"Density (normalized)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Settings\n",
    "The Test setting sets the test conditions in ingestion.\n",
    "This includes what systematics you want and how many psuedo experiments you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SETTINGS = {\n",
    "    \"systematics\": {  # Systematics to use\n",
    "        \"tes\": False,  # tau energy scale\n",
    "        \"jes\": False,  # jet energy scale\n",
    "        \"soft_met\": False,  # soft term in MET\n",
    "        \"ttbar_scale\": False,  # W boson scale factor\n",
    "        \"diboson_scale\": False,  # Diboson scale factor\n",
    "        \"bkg_scale\": False,  # Background scale factor\n",
    "    },\n",
    "    \"num_pseudo_experiments\": 25,  # Number of pseudo-experiments to run per set\n",
    "    \"num_of_sets\": 25,  # Number of sets of pseudo-experiments to run\n",
    "}\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_settings = TEST_SETTINGS.copy()\n",
    "\n",
    "random_state = np.random.RandomState(RANDOM_SEED)\n",
    "test_settings[\"ground_truth_mus\"] = (\n",
    "    random_state.uniform(0.1, 3, test_settings[\"num_of_sets\"])\n",
    ").tolist()\n",
    "\n",
    "random_settings_file = os.path.join(output_dir, \"test_settings.json\")\n",
    "with open(random_settings_file, \"w\") as f:\n",
    "    json.dump(test_settings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.ingestion import Ingestion\n",
    "\n",
    "ingestion = Ingestion(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize submission\n",
    "ingestion.init_submission(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit submission\n",
    "ingestion.fit_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "data.load_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict submission\n",
    "ingestion.predict_submission(test_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestion.process_results_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "ingestion.save_result(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "sys.path.append(os.getcwd())\n",
    "import sample_code_submission.feature_analysis as fa\n",
    "importlib.reload(fa)\n",
    " \n",
    "print(\"Top 10 minimal dependent features:\", fa.minimal_dependent_features(data_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score\n",
    "1. Compute Scores\n",
    "2. Visualize Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.score import Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Score\n",
    "score = Scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_dir)\n",
    "score.load_ingestion_results(prediction_dir=output_dir, score_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Score\n",
    "score.compute_scores(test_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.visualization import visualize_scatter\n",
    "\n",
    "# Visualize scatter plot of ground truth mu and predicted mu\n",
    "visualize_scatter(\n",
    "    ingestion_result_dict=ingestion.results_dict,\n",
    "    ground_truth_mus=test_settings[\"ground_truth_mus\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m HiggsML.score --prediction $output_dir --output $output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
