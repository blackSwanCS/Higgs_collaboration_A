{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750332ba",
   "metadata": {},
   "source": [
    "Modules nécessaires : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf468b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from HiggsML.ingestion import Ingestion\n",
    "from HiggsML.datasets import download_dataset\n",
    "from sample_code_submission.neural_network import NeuralNetwork\n",
    "from sys import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from numpy.random import RandomState\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284184d",
   "metadata": {},
   "source": [
    "Charger les données : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22752b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:09:38,578 - HiggsML.datasets     - INFO     - Handling as dataset name: blackSwan_data\n",
      "2025-06-04 14:09:38,580 - HiggsML.datasets     - INFO     - Current working directory: c:\\Users\\leand\\Desktop\\EI Higgs\\Higgs_collaboration_A\n",
      "2025-06-04 14:09:38,633 - HiggsML.datasets     - INFO     - Total rows: 2000000\n",
      "2025-06-04 14:09:38,635 - HiggsML.datasets     - INFO     - Test size: 600000\n",
      "2025-06-04 14:09:38,723 - HiggsML.datasets     - INFO     - Selected train size: 1400000\n",
      "2025-06-04 14:09:39,959 - HiggsML.datasets     - INFO     - Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "data = download_dataset(\n",
    "    \"blackSwan_data\"\n",
    ")  # change to \"blackSwan_data\" for the actual data\n",
    "\n",
    "# load train set\n",
    "data.load_train_set()\n",
    "data_set = data.get_train_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596b9c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_set[\"labels\"]\n",
    "weights = data_set[\"weights\"]\n",
    "detailed_label = data_set[\"detailed_labels\"]\n",
    "keys = np.unique(detailed_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ca9ab",
   "metadata": {},
   "source": [
    "Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837cf465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory is c:\\Users\\leand\\Desktop\\EI Higgs\\Higgs_collaboration_A\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.getcwd()\n",
    "print(\"Root directory is\", root_dir)\n",
    "submission_dir = os.path.join(root_dir, \"sample_code_submission\")\n",
    "\n",
    "# The directory where results and other outputs from the participant's code will be written\n",
    "output_dir = os.path.join(root_dir, \"sample_result_submission\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee9cee",
   "metadata": {},
   "source": [
    "Import Submission Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c8ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path.append(submission_dir)\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de4445",
   "metadata": {},
   "source": [
    "Testing Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4461446",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SETTINGS = {\n",
    "    \"systematics\": {  # Systematics to use\n",
    "        \"tes\": False,  # tau energy scale\n",
    "        \"jes\": False,  # jet energy scale\n",
    "        \"soft_met\": False,  # soft term in MET\n",
    "        \"ttbar_scale\": False,  # W boson scale factor\n",
    "        \"diboson_scale\": False,  # Diboson scale factor\n",
    "        \"bkg_scale\": False,  # Background scale factor\n",
    "    },\n",
    "    \"num_pseudo_experiments\": 25,  # Number of pseudo-experiments to run per set\n",
    "    \"num_of_sets\": 25,  # Number of sets of pseudo-experiments to run\n",
    "}\n",
    "\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab81ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_settings = TEST_SETTINGS.copy()\n",
    "\n",
    "random_state = np.random.RandomState(RANDOM_SEED)\n",
    "test_settings[\"ground_truth_mus\"] = (\n",
    "    random_state.uniform(0.1, 3, test_settings[\"num_of_sets\"])\n",
    ").tolist()\n",
    "\n",
    "random_settings_file = os.path.join(output_dir, \"test_settings.json\")\n",
    "with open(random_settings_file, \"w\") as f:\n",
    "    json.dump(test_settings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5408baf",
   "metadata": {},
   "source": [
    "Boucle sur \"Ingestion\" en faisant varier epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6a2aa",
   "metadata": {},
   "source": [
    "Fonction bouclée: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f196ee94",
   "metadata": {},
   "source": [
    "Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimization(train_data): \n",
    "    activation_fn = {\"relu\", \"sigmoid\"}\n",
    "    sigmax=0\n",
    "    L=[]\n",
    "    for fn in activation_fn :\n",
    "        ingestion = Ingestion(data)\n",
    "        # initialize submission\n",
    "        ingestion.init_submission(Model, \"NN\")\n",
    "        ingestion.model.model.activation = fn\n",
    "        print(ingestion.model.model.activation)\n",
    "        ingestion.fit_submission()\n",
    "        sig1 = ingestion.model.model.significance_2(test_labels=ingestion.model.training_set[\"labels\"],test_weights=ingestion.model.training_set[\"weights\"])\n",
    "        L.append((fn, sig1))\n",
    "        #visualisation des données :\n",
    "        if sig1>sigmax: \n",
    "            sigmax = sig1\n",
    "            fn_max = fn\n",
    "    return sigmax, fn_max, L\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d0e05",
   "metadata": {},
   "source": [
    "Il y a plusieurs problématique : \n",
    "Comment modifier une variable epochs de notre "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1589e",
   "metadata": {},
   "source": [
    "Lancement de la boucle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b636925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:09:41,112 - HiggsML.ingestion    - INFO     - Initializing Submmited Model\n",
      "2025-06-04 14:09:41,143 - HiggsML.datasets     - INFO     - Selected train size: 80000\n",
      "2025-06-04 14:09:41,635 - HiggsML.datasets     - INFO     - Data loaded successfully\n",
      "2025-06-04 14:09:41,667 - HiggsML.datasets     - INFO     - Selected train size: 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:  (80000, 28)\n",
      "Training Labels:  (80000,)\n",
      "Training Weights:  (80000,)\n",
      "sum_signal_weights:  678.1138992144495\n",
      "sum_bkg_weights:  105040.88610078552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:09:42,142 - HiggsML.datasets     - INFO     - Data loaded successfully\n",
      "2025-06-04 14:09:42,164 - HiggsML.datasets     - INFO     - Selected train size: 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valid Data:  (10000, 28)\n",
      "Valid Labels:  (10000,)\n",
      "Valid Weights:  (10000,)\n",
      "sum_signal_weights:  680.719996621049\n",
      "sum_bkg_weights:  105038.28000337898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:09:42,562 - HiggsML.datasets     - INFO     - Data loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holdout Data:  (10000, 28)\n",
      "Holdout Labels:  (10000,)\n",
      "Holdout Weights:  (10000,)\n",
      "sum_signal_weights:  677.7287697327586\n",
      "sum_bkg_weights:  105041.27123026722\n",
      " \n",
      " \n",
      "Training Data:  (80000, 28)\n",
      "DEBUG: model_type = 'NN'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NeuralNetwork' object has no attribute 'activation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moptimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m, in \u001b[0;36moptimization\u001b[1;34m(train_data)\u001b[0m\n\u001b[0;32m      6\u001b[0m ingestion \u001b[38;5;241m=\u001b[39m Ingestion(data)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# initialize submission\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mingestion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_submission\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m ingestion\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m fn\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(ingestion\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mactivation)\n",
      "File \u001b[1;32mc:\\Users\\leand\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\HiggsML\\ingestion.py:129\u001b[0m, in \u001b[0;36mIngestion.init_submission\u001b[1;34m(self, Model, model_type)\u001b[0m\n\u001b[0;32m    126\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing Submmited Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mHiggsML\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msystematics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m systematics\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_train_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_train_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystematics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystematics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdelete_train_set()\n",
      "File \u001b[1;32mc:\\Users\\leand\\Desktop\\EI Higgs\\Higgs_collaboration_A\\sample_code_submission\\model.py:150\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, get_train_set, systematics, model_type)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNN\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneural_network\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeuralNetwork\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_model\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msample_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SampleModel\n",
      "File \u001b[1;32mc:\\Users\\leand\\Desktop\\EI Higgs\\Higgs_collaboration_A\\sample_code_submission\\neural_network.py:19\u001b[0m, in \u001b[0;36mNeuralNetwork.__init__\u001b[1;34m(self, train_data)\u001b[0m\n\u001b[0;32m     16\u001b[0m n_dim \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#Vecteur de dimension n_dim en entrée\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m10\u001b[39m, input_dim\u001b[38;5;241m=\u001b[39mn_dim, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NeuralNetwork' object has no attribute 'activation'"
     ]
    }
   ],
   "source": [
    "optimization(data_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
