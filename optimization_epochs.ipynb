{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750332ba",
   "metadata": {},
   "source": [
    "Modules nécessaires : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf468b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from HiggsML.ingestion import Ingestion\n",
    "from HiggsML.datasets import download_dataset\n",
    "from sample_code_submission.neural_network import NeuralNetwork\n",
    "from sys import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from numpy.random import RandomState\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284184d",
   "metadata": {},
   "source": [
    "Charger les données : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22752b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = download_dataset(\n",
    "    \"blackSwan_data\"\n",
    ")  # change to \"blackSwan_data\" for the actual data\n",
    "\n",
    "# load train set\n",
    "data.load_train_set()\n",
    "data_set = data.get_train_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b9c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_set[\"labels\"]\n",
    "weights = data_set[\"weights\"]\n",
    "detailed_label = data_set[\"detailed_labels\"]\n",
    "keys = np.unique(detailed_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ca9ab",
   "metadata": {},
   "source": [
    "Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837cf465",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "print(\"Root directory is\", root_dir)\n",
    "submission_dir = os.path.join(root_dir, \"sample_code_submission\")\n",
    "\n",
    "# The directory where results and other outputs from the participant's code will be written\n",
    "output_dir = os.path.join(root_dir, \"sample_result_submission\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee9cee",
   "metadata": {},
   "source": [
    "Import Submission Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path.append(submission_dir)\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de4445",
   "metadata": {},
   "source": [
    "Testing Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4461446",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SETTINGS = {\n",
    "    \"systematics\": {  # Systematics to use\n",
    "        \"tes\": False,  # tau energy scale\n",
    "        \"jes\": False,  # jet energy scale\n",
    "        \"soft_met\": False,  # soft term in MET\n",
    "        \"ttbar_scale\": False,  # W boson scale factor\n",
    "        \"diboson_scale\": False,  # Diboson scale factor\n",
    "        \"bkg_scale\": False,  # Background scale factor\n",
    "    },\n",
    "    \"num_pseudo_experiments\": 25,  # Number of pseudo-experiments to run per set\n",
    "    \"num_of_sets\": 25,  # Number of sets of pseudo-experiments to run\n",
    "}\n",
    "\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab81ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_settings = TEST_SETTINGS.copy()\n",
    "\n",
    "random_state = np.random.RandomState(RANDOM_SEED)\n",
    "test_settings[\"ground_truth_mus\"] = (\n",
    "    random_state.uniform(0.1, 3, test_settings[\"num_of_sets\"])\n",
    ").tolist()\n",
    "\n",
    "random_settings_file = os.path.join(output_dir, \"test_settings.json\")\n",
    "with open(random_settings_file, \"w\") as f:\n",
    "    json.dump(test_settings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5408baf",
   "metadata": {},
   "source": [
    "Boucle sur \"Ingestion\" en faisant varier epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d11e4b4",
   "metadata": {},
   "source": [
    "Graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d26336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphique(S, E):\n",
    "    plt.plot(S, E, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Significance en fonction de epochs')\n",
    "    plt.xlabel('significance')\n",
    "    plt.ylabel('epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fbd1f0",
   "metadata": {},
   "source": [
    "Calcul AUC : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f196ee94",
   "metadata": {},
   "source": [
    "Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimization(train_data): \n",
    "    L_epochs = np.linspace(50, 50, 1)\n",
    "    sigmax = 0\n",
    "    epochs_max = 1\n",
    "    S = []\n",
    "    E = []\n",
    "    for k in range(len(L_epochs)):\n",
    "        ingestion = Ingestion(data)\n",
    "        # initialize submission\n",
    "        ingestion.init_submission(Model, \"NN\")\n",
    "        ingestion.model.model.epochs = int(L_epochs[k])\n",
    "        print(ingestion.model.model.epochs)\n",
    "        ingestion.fit_submission()\n",
    "        sig1 = ingestion.model.model.significance_2(test_labels=ingestion.model.training_set[\"labels\"],test_weights=ingestion.model.training_set[\"weights\"])\n",
    "        #visualisation des données :\n",
    "        S.append(sig1)\n",
    "        E.append(int(L_epochs[k]))\n",
    "        if sig1>sigmax: \n",
    "            sigmax = sig1\n",
    "            epochs_max = int(L_epochs[k])\n",
    "    graphique(S, E)\n",
    "    return sigmax, epochs_max\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d0e05",
   "metadata": {},
   "source": [
    "Il y a plusieurs problématique : \n",
    "Comment modifier une variable epochs de notre "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4458948a",
   "metadata": {},
   "source": [
    "test_labels=ingestion.model.training_set[\"labels\"],test_weights=ingestion.model.training_set[\"weights\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1589e",
   "metadata": {},
   "source": [
    "Lancement de la boucle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1748e",
   "metadata": {},
   "source": [
    "A l'aide des autres programmes d'optimisations, on a obtenu batchsize : 120, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0091df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d74353f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b636925",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization(data_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
